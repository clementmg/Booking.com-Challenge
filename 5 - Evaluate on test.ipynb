{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from statistics import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_data.pkl\", \"rb\") as f:\n",
    "    test_set, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "      <th>is_new_trip</th>\n",
       "      <th>is_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>20764</td>\n",
       "      <td>tablet</td>\n",
       "      <td>9452</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>1174942_1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>2016-06-04</td>\n",
       "      <td>59001</td>\n",
       "      <td>tablet</td>\n",
       "      <td>9452</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>1174942_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-04</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>15186</td>\n",
       "      <td>tablet</td>\n",
       "      <td>9452</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>1174942_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>2016-06-10</td>\n",
       "      <td>?</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>?</td>\n",
       "      <td>1174942_1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>60237</td>\n",
       "      <td>desktop</td>\n",
       "      <td>5755</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Kangan</td>\n",
       "      <td>1311136_1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58651</th>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>36170</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Carpathia</td>\n",
       "      <td>97967_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58652</th>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>17990</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Carpathia</td>\n",
       "      <td>97967_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58653</th>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>2016-08-15</td>\n",
       "      <td>62185</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Axphain</td>\n",
       "      <td>97967_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58654</th>\n",
       "      <td>2016-08-15</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>56503</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Axphain</td>\n",
       "      <td>97967_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58655</th>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>?</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>?</td>\n",
       "      <td>97967_1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58656 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          checkin    checkout city_id device_class  affiliate_id  \\\n",
       "0      2016-06-01  2016-06-03   20764       tablet          9452   \n",
       "1      2016-06-03  2016-06-04   59001       tablet          9452   \n",
       "2      2016-06-04  2016-06-07   15186       tablet          9452   \n",
       "3      2016-06-07  2016-06-10       ?      desktop           384   \n",
       "4      2016-05-11  2016-05-13   60237      desktop          5755   \n",
       "...           ...         ...     ...          ...           ...   \n",
       "58651  2016-08-09  2016-08-11   36170      desktop          9924   \n",
       "58652  2016-08-11  2016-08-13   17990      desktop          9924   \n",
       "58653  2016-08-13  2016-08-15   62185      desktop          9924   \n",
       "58654  2016-08-15  2016-08-16   56503      desktop          9924   \n",
       "58655  2016-08-16  2016-08-17       ?      desktop          9924   \n",
       "\n",
       "      booker_country hotel_country   utrip_id  is_new_trip  is_target  \n",
       "0             Gondal  Santa Prisca  1174942_1         True      False  \n",
       "1             Gondal  Santa Prisca  1174942_1        False      False  \n",
       "2             Gondal  Santa Prisca  1174942_1        False      False  \n",
       "3             Gondal             ?  1174942_1        False       True  \n",
       "4             Gondal        Kangan  1311136_1         True      False  \n",
       "...              ...           ...        ...          ...        ...  \n",
       "58651        Elbonia     Carpathia    97967_1        False      False  \n",
       "58652        Elbonia     Carpathia    97967_1        False      False  \n",
       "58653        Elbonia       Axphain    97967_1        False      False  \n",
       "58654        Elbonia       Axphain    97967_1        False      False  \n",
       "58655        Elbonia             ?    97967_1        False       True  \n",
       "\n",
       "[58656 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Preprocessing_encoders.pkl\", \"rb\") as f:\n",
    "    encode_cities, encode_devices, encode_affiliate_id, encode_hotel_country, encode_booker_country = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"normalized_values.pkl\", \"rb\") as f:\n",
    "    normalized_values = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.set_index(\"utrip_id\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, concatenate, Input, TimeDistributed, Layer, Bidirectional, Softmax, Multiply, Lambda, GRU\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras import activations\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "reg = L2(l2=0.0001)\n",
    "embedding_size = 300\n",
    "num_cities = 39901\n",
    "info_features_length = 4\n",
    "dropout = 0.5\n",
    "\n",
    "trips_sequences_input = Input(shape=(None,)) \n",
    "info_input = Input(shape=(info_features_length))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#First RNN on cities with Embeddings\n",
    "emb_layer = Embedding(output_dim=embedding_size, input_dim=num_cities, input_length=None,\n",
    "                      mask_zero=False, name=\"city_embeddings\", embeddings_regularizer=reg)\n",
    "\n",
    "emb_cities = emb_layer(trips_sequences_input) \n",
    "lstm_cities_1 = GRU(100, dropout=dropout, return_sequences=True,\n",
    "                    kernel_regularizer=reg)(emb_cities)\n",
    "  \n",
    "\n",
    "lstm_cities_2 = GRU(100, dropout=dropout, return_sequences=True,\n",
    "                  kernel_regularizer=reg)(lstm_cities_1)\n",
    "\n",
    "\n",
    "#Add attention layer\n",
    "attention=TimeDistributed(Dense(1))(lstm_cities_2)\n",
    "attention=Softmax(axis=1)(attention)\n",
    "context=Multiply()([attention,lstm_cities_2])\n",
    "out=Lambda(lambda x: K.sum(x,axis=1))(context)    \n",
    "\n",
    "\n",
    "\n",
    "concat = concatenate([out, info_input]) \n",
    "\n",
    "\n",
    "#Combine two RNN with features\n",
    "#pre_output = Dense()\n",
    "output = Dense(num_cities, activation='softmax')(concat) \n",
    "\n",
    "\n",
    " \n",
    "model = Model(inputs=[trips_sequences_input, info_input], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import sparse_top_k_categorical_accuracy\n",
    "learning_rate = 0.0003\n",
    "batch_size = 512\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipvalue=.25)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",        #custom_loss(model, embedding_size, 1, batch_size), # Call the loss function with the model\n",
    "              metrics=['sparse_top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "model.load_weights(\"improvement-22-0.49.hdf5\") #, custom_objects={'loss': K.sparse_categorical_crossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_timesteps(t, len_trip, proportion=3):\n",
    "    max_id_to_drop = len(t) // 3\n",
    "    n = int(max_id_to_drop * pow(np.random.rand(), 0.3)) + 1 #random number of indexes to drop\n",
    "    for i in range(n):\n",
    "        to_skip = int(len_trip * pow(np.random.rand(), 0.3)) #more likely to skip a step towrds the end to add confusion\n",
    "        t = np.delete(t, to_skip, axis=0)\n",
    "        len_trip -= 1 #one time step was removed, so the trip is 1 time step smaller\n",
    "        \n",
    "    return t, len_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy import savez_compressed, load\n",
    "\n",
    "def predictions_generator(filename1, filename2, batch_size=512, skip=False):\n",
    "    #initiate a batch count for each size of trips\n",
    "    batch_count = {k: 0 for k in range(50)}\n",
    "    inputs = {k: [] for k in range(50)}\n",
    "    while True:\n",
    "        #load files\n",
    "        trip_sequences = load(filename1, allow_pickle=True)[\"arr_0\"]\n",
    "        trip_infos = load(filename2, allow_pickle=True)[\"arr_0\"]\n",
    "        \n",
    "        for i in range(len(trip_sequences)):\n",
    "        \n",
    "            #consider trip i\n",
    "            trip_sequence = trip_sequences[i]\n",
    "            trip_info = trip_infos[i]\n",
    "            len_trip = len(trip_sequence)\n",
    "            \n",
    "            if (skip) & (len_trip > 3):\n",
    "                #randomly skip one or more timesteps:\n",
    "                random.seed()\n",
    "                trip_sequence, len_trip = drop_timesteps(trip_sequence, len_trip, 3)\n",
    "            \n",
    "            #add info to corresponding  size\n",
    "            inputs[len_trip].append([trip_sequence, trip_info])\n",
    "            batch_count[len_trip] += 1\n",
    "            \n",
    "            if batch_count[len_trip] == batch_size:\n",
    "                X_trip = np.array([t[0] for t in inputs[len_trip]], dtype=\"int32\")\n",
    "                X_info = np.array([t[1] for t in inputs[len_trip]], dtype=\"float32\")\n",
    "                #yield the data to feed the \n",
    "                yield [X_trip, X_info]\n",
    "                inputs[len_trip] = []\n",
    "                batch_count[len_trip] = 0\n",
    "               \n",
    "            \n",
    "\n",
    "index = load(\"X_test_index.npz\", allow_pickle=True)[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed, load\n",
    "import random\n",
    "def getData(filename1, filename2, filename3, batch_size=512, skip=0.2, train=True):\n",
    "    #initiate a batch count for each size of trips\n",
    "    batch_count = {k: 0 for k in range(50)}\n",
    "    inputs = {k: [] for k in range(50)}\n",
    "    targets = {k: [] for k in range(50)}\n",
    "    while True:\n",
    "        #load files\n",
    "        trip_sequences = load(filename1, allow_pickle=True)[\"arr_0\"]\n",
    "        trip_infos = load(filename2, allow_pickle=True)[\"arr_0\"]\n",
    "        predictions = load(filename3, allow_pickle=True)[\"arr_0\"]\n",
    "        \n",
    "        if train:\n",
    "          random.seed()\n",
    "          #Shuffle\n",
    "          to_shuffle = list(zip(trip_sequences, trip_infos, predictions))\n",
    "          random.shuffle(to_shuffle)\n",
    "          trip_sequences, trip_infos, predictions = zip(*to_shuffle)\n",
    "\n",
    "        #trip_sequences = np.array(trip_sequences)\n",
    "        #trip_infos = np.array(trip_infos) \n",
    "        predictions = np.array(predictions, dtype=\"int32\")\n",
    "        \n",
    "        for i in range(len(trip_sequences)):\n",
    "          \n",
    "            #consider trip i\n",
    "            trip_sequence = trip_sequences[i]\n",
    "            trip_info = trip_infos[i]\n",
    "            prediction = predictions[i]\n",
    "            len_trip = len(trip_sequence)\n",
    "            \n",
    "            if (train) & (len_trip > 3):\n",
    "              #randomly skip one time step:\n",
    "              random.seed()\n",
    "              n = np.random.randint(100)\n",
    "              if n / 100 < skip:\n",
    "                #random step to skip:\n",
    "                trip_sequence, len_trip = drop_timesteps(trip_sequence, len_trip)\n",
    "            \n",
    "            #add info to corresponding  size\n",
    "            inputs[len_trip].append([trip_sequence, trip_info])\n",
    "            targets[len_trip].append(prediction)\n",
    "            batch_count[len_trip] += 1\n",
    "            \n",
    "            if batch_count[len_trip] == batch_size:\n",
    "                X_trip = np.array([t[0] for t in inputs[len_trip]], dtype='float32')\n",
    "                X_info = np.array([t[1] for t in inputs[len_trip]], dtype='float32')\n",
    "                y = np.array(targets[len_trip]).reshape(batch_size,)\n",
    "                #yield the data to feed the \n",
    "                yield [X_trip, X_info], y\n",
    "                inputs[len_trip] = []\n",
    "                targets[len_trip] = []\n",
    "                batch_count[len_trip] = 0\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = getData(\"X_test_trip.npz\", \"X_test_info.npz\",\"y_test.npz\",\n",
    "                                        batch_size=256, skip=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 47ms/step - loss: 12.4253 - sparse_top_k_categorical_accuracy: 0.4914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.425256729125977, 0.4914434552192688]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator, steps=len(index) // 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trips = load(\"X_test_trip.npz\", allow_pickle=True)[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"consecutive_cities.pkl\", \"rb\") as f:\n",
    "    consec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_highly_consecutive_cities(threshold=0.06):\n",
    "    selected_cities = [city for city in consec.keys() if consec[city] > threshold]\n",
    "    s = encode_cities.transform(selected_cities) #encoded\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify column 0\n",
    "def adapt_4th_pred(p, s):\n",
    "    last_pred = p[4]\n",
    "    #if not frequently followed by duplicate, do not consider it\n",
    "    if last_pred not in s:\n",
    "        #return 4th choice of model\n",
    "        return p[0]\n",
    "    #else\n",
    "    #if last pred already predicted\n",
    "    if last_pred in p[:4].values:\n",
    "        return p[0]\n",
    "    #else\n",
    "    return p[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"final_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_generator(generator, topn=4, to_pred=4000, use_last=False):\n",
    "    \n",
    "    preds = model.predict(generator, steps=to_pred, batch_size=1)\n",
    "    sorted_preds = np.array(preds).argsort(axis=1) #sort them along axis\n",
    "    res_df = pd.DataFrame(sorted_preds[:,-topn:]) #select topn\n",
    "    \n",
    "    if use_last:\n",
    "        s = select_highly_consecutive_cities()\n",
    "        last_cities = [trip[-1] for trip in test_trips[:to_pred]]\n",
    "        #we use the last city as a prediction\n",
    "        res_df[4] = last_cities\n",
    "        res_df[0] = res_df.apply(lambda x: adapt_4th_pred(x, s), axis=1)\n",
    "        res_df.drop(4, inplace=True, axis=1)\n",
    "    \n",
    "    #inverse transform\n",
    "    for i in range(4):\n",
    "        res_df.iloc[:,i] = encode_cities.inverse_transform(res_df.iloc[:,i])\n",
    "        \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "skip_generator = predictions_generator(\"X_test_trip.npz\", \"X_test_info.npz\",\n",
    "                                        batch_size=batch_size, skip=True)\n",
    "\n",
    "normal_generator = predictions_generator(\"X_test_trip.npz\", \"X_test_info.npz\",\n",
    "                                        batch_size=batch_size, skip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 2000\n",
    "res_df = predict_from_generator(normal_generator, use_last=True, to_pred=n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of good reco: 0.4965%\n"
     ]
    }
   ],
   "source": [
    "res_df[\"true\"] = y_test.loc[y_test.index.isin(index[:n_pred])].city_id.values\n",
    "res_df[\"good\"] = res_df.apply(lambda x: x[\"true\"] in x[[0, 1, 2, 3]].values, axis=1)\n",
    "print(f\"Percentage of good reco: {res_df.good.sum() / res_df.shape[0]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of top reco: 0.2655%\n"
     ]
    }
   ],
   "source": [
    "res_df[\"top1\"] = res_df.apply(lambda x: x[\"true\"] in x[[3]].values, axis=1)\n",
    "print(f\"Percentage of top reco: {res_df.top1.sum() / res_df.shape[0]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47499    46\n",
       "2416     21\n",
       "62185    16\n",
       "17013    15\n",
       "26436    15\n",
       "         ..\n",
       "25286     1\n",
       "25025     1\n",
       "58819     1\n",
       "52933     1\n",
       "40960     1\n",
       "Name: true, Length: 192, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.loc[res_df.top1].true.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = res_df.loc[res_df.good].true.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = res_df.true.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in all_preds.keys():\n",
    "    if k not in correct_preds.keys():\n",
    "        #no good predictions\n",
    "        all_preds[k] = 0.0\n",
    "        continue\n",
    "    all_preds[k] = correct_preds[k] / all_preds[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{47499: 0.9444444444444444,\n",
       " 36063: 0.6486486486486487,\n",
       " 17013: 0.9230769230769231,\n",
       " 2416: 1.0,\n",
       " 21929: 0.6190476190476191,\n",
       " 26235: 0.8,\n",
       " 29770: 0.6111111111111112,\n",
       " 29319: 0.7058823529411765,\n",
       " 3763: 0.9411764705882353,\n",
       " 62185: 0.9411764705882353,\n",
       " 26436: 1.0,\n",
       " 4932: 0.875,\n",
       " 55763: 0.8666666666666667,\n",
       " 61320: 0.8571428571428571,\n",
       " 23921: 0.9285714285714286,\n",
       " 10485: 0.8571428571428571,\n",
       " 51765: 0.7692307692307693,\n",
       " 64876: 0.5384615384615384,\n",
       " 51291: 0.7692307692307693,\n",
       " 17127: 0.6923076923076923,\n",
       " 52815: 0.7692307692307693,\n",
       " 7410: 0.6923076923076923,\n",
       " 2078: 0.9166666666666666,\n",
       " 66648: 1.0,\n",
       " 51259: 0.8,\n",
       " 52818: 0.6,\n",
       " 8766: 0.8888888888888888,\n",
       " 8462: 1.0,\n",
       " 35160: 0.875,\n",
       " 46854: 0.875,\n",
       " 48483: 0.875,\n",
       " 51517: 0.5,\n",
       " 47976: 0.75,\n",
       " 38677: 0.8571428571428571,\n",
       " 60143: 1.0,\n",
       " 42356: 0.7142857142857143,\n",
       " 25025: 0.7142857142857143,\n",
       " 12308: 0.8571428571428571,\n",
       " 30520: 1.0,\n",
       " 19771: 0.7142857142857143,\n",
       " 382: 0.7142857142857143,\n",
       " 20345: 0.7142857142857143,\n",
       " 60222: 1.0,\n",
       " 65856: 0.7142857142857143,\n",
       " 22065: 0.5714285714285714,\n",
       " 55128: 1.0,\n",
       " 27404: 0.6666666666666666,\n",
       " 49668: 1.0,\n",
       " 45188: 0.5,\n",
       " 47759: 0.8333333333333334,\n",
       " 40521: 0.8333333333333334,\n",
       " 16521: 0.6666666666666666,\n",
       " 16888: 0.16666666666666666,\n",
       " 4202: 0.5,\n",
       " 28154: 0.6666666666666666,\n",
       " 17775: 0.3333333333333333,\n",
       " 67353: 0.3333333333333333,\n",
       " 55196: 0.5,\n",
       " 51135: 0.6,\n",
       " 57658: 0.6,\n",
       " 10092: 0.8,\n",
       " 63977: 0.8,\n",
       " 23714: 1.0,\n",
       " 26345: 0.2,\n",
       " 2748: 0.6,\n",
       " 65202: 0.8,\n",
       " 13530: 0.6,\n",
       " 8335: 0.4,\n",
       " 34342: 0.6,\n",
       " 43306: 0.6,\n",
       " 58178: 0.6,\n",
       " 6582: 1.0,\n",
       " 23940: 0.2,\n",
       " 37689: 0.0,\n",
       " 55: 0.6,\n",
       " 9608: 1.0,\n",
       " 31531: 0.75,\n",
       " 60632: 0.5,\n",
       " 2369: 1.0,\n",
       " 16612: 1.0,\n",
       " 3082: 0.25,\n",
       " 12426: 0.0,\n",
       " 18417: 0.75,\n",
       " 28115: 1.0,\n",
       " 64269: 0.75,\n",
       " 44103: 1.0,\n",
       " 1528: 0.75,\n",
       " 47527: 0.75,\n",
       " 9526: 0.5,\n",
       " 45682: 1.0,\n",
       " 16047: 0.75,\n",
       " 14646: 0.0,\n",
       " 58819: 0.5,\n",
       " 63151: 1.0,\n",
       " 64091: 0.5,\n",
       " 62611: 0.75,\n",
       " 41858: 0.5,\n",
       " 1187: 0.75,\n",
       " 37407: 0.3333333333333333,\n",
       " 64824: 0.6666666666666666,\n",
       " 36170: 0.6666666666666666,\n",
       " 6327: 1.0,\n",
       " 36435: 0.0,\n",
       " 4476: 0.3333333333333333,\n",
       " 47360: 0.6666666666666666,\n",
       " 7761: 0.3333333333333333,\n",
       " 58741: 0.6666666666666666,\n",
       " 11652: 0.3333333333333333,\n",
       " 4975: 0.6666666666666666,\n",
       " 46675: 1.0,\n",
       " 60274: 0.3333333333333333,\n",
       " 28273: 0.3333333333333333,\n",
       " 26904: 0.0,\n",
       " 49818: 1.0,\n",
       " 18820: 0.6666666666666666,\n",
       " 19333: 0.6666666666666666,\n",
       " 12887: 0.3333333333333333,\n",
       " 55284: 0.3333333333333333,\n",
       " 53859: 0.3333333333333333,\n",
       " 58974: 0.6666666666666666,\n",
       " 2122: 0.3333333333333333,\n",
       " 44869: 1.0,\n",
       " 48968: 0.3333333333333333,\n",
       " 1924: 0.6666666666666666,\n",
       " 59535: 1.0,\n",
       " 30688: 1.0,\n",
       " 8938: 0.0,\n",
       " 4790: 0.6666666666666666,\n",
       " 53363: 0.3333333333333333,\n",
       " 699: 0.6666666666666666,\n",
       " 5274: 0.0,\n",
       " 1940: 0.3333333333333333,\n",
       " 5085: 0.3333333333333333,\n",
       " 31870: 0.6666666666666666,\n",
       " 43736: 0.3333333333333333,\n",
       " 21555: 0.3333333333333333,\n",
       " 20392: 0.0,\n",
       " 19707: 0.0,\n",
       " 35850: 0.6666666666666666,\n",
       " 65322: 0.6666666666666666,\n",
       " 44320: 0.6666666666666666,\n",
       " 61487: 0.6666666666666666,\n",
       " 19448: 1.0,\n",
       " 56590: 1.0,\n",
       " 21766: 0.6666666666666666,\n",
       " 33118: 0.5,\n",
       " 11783: 0.0,\n",
       " 37874: 0.0,\n",
       " 45025: 0.5,\n",
       " 61859: 0.0,\n",
       " 42482: 1.0,\n",
       " 5612: 0.5,\n",
       " 5067: 0.5,\n",
       " 7611: 0.0,\n",
       " 50661: 0.0,\n",
       " 35193: 0.0,\n",
       " 35206: 0.5,\n",
       " 10994: 1.0,\n",
       " 31088: 0.5,\n",
       " 30240: 0.0,\n",
       " 58964: 0.5,\n",
       " 53633: 0.0,\n",
       " 19191: 0.0,\n",
       " 56062: 0.0,\n",
       " 56198: 0.5,\n",
       " 51999: 0.5,\n",
       " 17990: 0.0,\n",
       " 7192: 0.0,\n",
       " 27701: 1.0,\n",
       " 35811: 0.5,\n",
       " 7653: 0.0,\n",
       " 31873: 0.5,\n",
       " 9698: 0.5,\n",
       " 52567: 0.0,\n",
       " 6788: 0.5,\n",
       " 36073: 1.0,\n",
       " 33408: 0.5,\n",
       " 50260: 1.0,\n",
       " 6779: 1.0,\n",
       " 50453: 0.0,\n",
       " 8750: 1.0,\n",
       " 41524: 0.5,\n",
       " 4827: 0.0,\n",
       " 34123: 0.5,\n",
       " 29943: 1.0,\n",
       " 46411: 1.0,\n",
       " 66815: 1.0,\n",
       " 22297: 1.0,\n",
       " 950: 1.0,\n",
       " 42293: 0.0,\n",
       " 7549: 0.5,\n",
       " 64436: 1.0,\n",
       " 59914: 0.0,\n",
       " 25997: 1.0,\n",
       " 47378: 0.5,\n",
       " 9094: 0.0,\n",
       " 41432: 0.0,\n",
       " 15337: 0.0,\n",
       " 31890: 1.0,\n",
       " 39387: 0.0,\n",
       " 57820: 1.0,\n",
       " 64960: 0.0,\n",
       " 44466: 0.5,\n",
       " 56465: 1.0,\n",
       " 22868: 0.5,\n",
       " 56503: 0.5,\n",
       " 35495: 0.0,\n",
       " 26290: 0.5,\n",
       " 29907: 0.5,\n",
       " 27624: 0.5,\n",
       " 38912: 0.0,\n",
       " 39820: 1.0,\n",
       " 24783: 1.0,\n",
       " 51302: 0.0,\n",
       " 58522: 0.0,\n",
       " 15215: 1.0,\n",
       " 18554: 0.5,\n",
       " 3387: 0.0,\n",
       " 32392: 0.5,\n",
       " 11074: 1.0,\n",
       " 14549: 1.0,\n",
       " 63418: 1.0,\n",
       " 39097: 0.0,\n",
       " 65663: 1.0,\n",
       " 22252: 1.0,\n",
       " 38586: 0.5,\n",
       " 21480: 0.5,\n",
       " 41009: 1.0,\n",
       " 32713: 1.0,\n",
       " 61545: 0.0,\n",
       " 36905: 0.5,\n",
       " 1910: 1.0,\n",
       " 47635: 0.0,\n",
       " 55529: 1.0,\n",
       " 6090: 1.0,\n",
       " 18508: 0.0,\n",
       " 10489: 0.5,\n",
       " 61586: 0.0,\n",
       " 45135: 0.0,\n",
       " 13931: 0.0,\n",
       " 49063: 0.0,\n",
       " 52848: 1.0,\n",
       " 3674: 0.5,\n",
       " 32640: 0.0,\n",
       " 47389: 1.0,\n",
       " 27115: 0.5,\n",
       " 65690: 1.0,\n",
       " 55385: 0.0,\n",
       " 25286: 1.0,\n",
       " 26611: 0.0,\n",
       " 15564: 0.0,\n",
       " 6884: 0.0,\n",
       " 2140: 1.0,\n",
       " 39618: 0.0,\n",
       " 43745: 0.0,\n",
       " 47815: 0.0,\n",
       " 13602: 1.0,\n",
       " 65679: 0.0,\n",
       " 23243: 0.0,\n",
       " 64224: 0.0,\n",
       " 66261: 0.0,\n",
       " 735: 1.0,\n",
       " 24509: 0.0,\n",
       " 21197: 0.0,\n",
       " 15464: 0.0,\n",
       " 39641: 0.0,\n",
       " 30969: 0.0,\n",
       " 12388: 0.0,\n",
       " 19153: 0.0,\n",
       " 36959: 0.0,\n",
       " 31442: 1.0,\n",
       " 32867: 0.0,\n",
       " 20588: 1.0,\n",
       " 36967: 1.0,\n",
       " 47238: 0.0,\n",
       " 60058: 1.0,\n",
       " 56582: 1.0,\n",
       " 46861: 0.0,\n",
       " 57178: 0.0,\n",
       " 41620: 0.0,\n",
       " 657: 1.0,\n",
       " 22684: 0.0,\n",
       " 49283: 0.0,\n",
       " 2700: 0.0,\n",
       " 6849: 0.0,\n",
       " 18673: 1.0,\n",
       " 47752: 0.0,\n",
       " 59542: 0.0,\n",
       " 27267: 0.0,\n",
       " 29314: 0.0,\n",
       " 8344: 0.0,\n",
       " 39553: 0.0,\n",
       " 4249: 0.0,\n",
       " 6811: 0.0,\n",
       " 58038: 0.0,\n",
       " 56589: 0.0,\n",
       " 24853: 0.0,\n",
       " 49855: 0.0,\n",
       " 1466: 0.0,\n",
       " 29442: 0.0,\n",
       " 47799: 0.0,\n",
       " 4208: 0.0,\n",
       " 30836: 0.0,\n",
       " 39029: 0.0,\n",
       " 31413: 0.0,\n",
       " 41651: 0.0,\n",
       " 21168: 0.0,\n",
       " 14457: 0.0,\n",
       " 33451: 0.0,\n",
       " 10920: 0.0,\n",
       " 34223: 0.0,\n",
       " 60069: 0.0,\n",
       " 9304: 0.0,\n",
       " 673: 0.0,\n",
       " 55383: 0.0,\n",
       " 17157: 1.0,\n",
       " 35563: 0.0,\n",
       " 46335: 0.0,\n",
       " 45923: 0.0,\n",
       " 14361: 1.0,\n",
       " 50017: 0.0,\n",
       " 41822: 0.0,\n",
       " 62593: 1.0,\n",
       " 27485: 0.0,\n",
       " 29301: 0.0,\n",
       " 31577: 1.0,\n",
       " 25431: 1.0,\n",
       " 40987: 1.0,\n",
       " 23382: 1.0,\n",
       " 66976: 0.0,\n",
       " 21328: 1.0,\n",
       " 9039: 1.0,\n",
       " 5565: 1.0,\n",
       " 60237: 0.0,\n",
       " 52042: 0.0,\n",
       " 34473: 0.0,\n",
       " 26656: 0.0,\n",
       " 45925: 0.0,\n",
       " 18578: 0.0,\n",
       " 18980: 1.0,\n",
       " 15209: 1.0,\n",
       " 24582: 0.0,\n",
       " 43017: 0.0,\n",
       " 33667: 0.0,\n",
       " 18443: 0.0,\n",
       " 37761: 1.0,\n",
       " 35710: 0.0,\n",
       " 56189: 0.0,\n",
       " 29562: 1.0,\n",
       " 52088: 1.0,\n",
       " 15990: 0.0,\n",
       " 26086: 0.0,\n",
       " 43021: 0.0,\n",
       " 67495: 0.0,\n",
       " 45073: 0.0,\n",
       " 4756: 0.0,\n",
       " 52797: 0.0,\n",
       " 11115: 0.0,\n",
       " 43882: 0.0,\n",
       " 34835: 0.0,\n",
       " 55329: 0.0,\n",
       " 20514: 0.0,\n",
       " 65013: 0.0,\n",
       " 47144: 0.0,\n",
       " 28733: 1.0,\n",
       " 19210: 0.0,\n",
       " 36929: 0.0,\n",
       " 10308: 0.0,\n",
       " 49927: 0.0,\n",
       " 29446: 0.0,\n",
       " 39685: 0.0,\n",
       " 49924: 0.0,\n",
       " 17155: 0.0,\n",
       " 27394: 0.0,\n",
       " 39680: 1.0,\n",
       " 30888: 0.0,\n",
       " 63563: 0.0,\n",
       " 15343: 1.0,\n",
       " 27379: 0.0,\n",
       " 34972: 0.0,\n",
       " 2801: 1.0,\n",
       " 37616: 0.0,\n",
       " 20564: 0.0,\n",
       " 56651: 1.0,\n",
       " 51258: 0.0,\n",
       " 29461: 0.0,\n",
       " 25390: 0.0,\n",
       " 52033: 0.0,\n",
       " 28718: 0.0,\n",
       " 54077: 1.0,\n",
       " 6971: 0.0,\n",
       " 30768: 1.0,\n",
       " 19254: 0.0,\n",
       " 47920: 0.0,\n",
       " 17199: 0.0,\n",
       " 15968: 0.0,\n",
       " 25367: 0.0,\n",
       " 25388: 0.0,\n",
       " 55610: 1.0,\n",
       " 20512: 0.0,\n",
       " 15140: 0.0,\n",
       " 32821: 1.0,\n",
       " 43062: 0.0,\n",
       " 21276: 0.0,\n",
       " 2840: 0.0,\n",
       " 21118: 1.0,\n",
       " 31057: 1.0,\n",
       " 12445: 0.0,\n",
       " 2305: 0.0,\n",
       " 30796: 1.0,\n",
       " 42276: 0.0,\n",
       " 12722: 0.0,\n",
       " 8468: 1.0,\n",
       " 33201: 0.0,\n",
       " 65966: 1.0,\n",
       " 49430: 0.0,\n",
       " 27052: 0.0,\n",
       " 18875: 0.0,\n",
       " 2329: 0.0,\n",
       " 39547: 0.0,\n",
       " 8476: 0.0,\n",
       " 2334: 0.0,\n",
       " 15583: 0.0,\n",
       " 41247: 0.0,\n",
       " 43428: 0.0,\n",
       " 47396: 0.0,\n",
       " 41378: 0.0,\n",
       " 59808: 0.0,\n",
       " 57619: 0.0,\n",
       " 22968: 0.0,\n",
       " 57787: 0.0,\n",
       " 25946: 0.0,\n",
       " 20958: 0.0,\n",
       " 53508: 0.0,\n",
       " 43269: 0.0,\n",
       " 44503: 0.0,\n",
       " 23628: 0.0,\n",
       " 13676: 1.0,\n",
       " 16648: 0.0,\n",
       " 37335: 1.0,\n",
       " 58607: 0.0,\n",
       " 47548: 0.0,\n",
       " 31627: 0.0,\n",
       " 25749: 0.0,\n",
       " 4555: 0.0,\n",
       " 35085: 1.0,\n",
       " 40131: 0.0,\n",
       " 46152: 0.0,\n",
       " 3510: 0.0,\n",
       " 35090: 0.0,\n",
       " 6557: 0.0,\n",
       " 57620: 0.0,\n",
       " 17692: 0.0,\n",
       " 14864: 0.0,\n",
       " 6512: 0.0,\n",
       " 47470: 0.0,\n",
       " 62564: 0.0,\n",
       " 25855: 0.0,\n",
       " 55653: 1.0,\n",
       " 57700: 0.0,\n",
       " 49475: 0.0,\n",
       " 51555: 0.0,\n",
       " 63812: 0.0,\n",
       " 6469: 1.0,\n",
       " 51664: 0.0,\n",
       " 12642: 0.0,\n",
       " 24927: 0.0,\n",
       " 24904: 1.0,\n",
       " 29019: 0.0,\n",
       " 58439: 0.0,\n",
       " 65868: 0.0,\n",
       " 45399: 0.0,\n",
       " 39252: 0.0,\n",
       " 44929: 1.0,\n",
       " 51572: 0.0,\n",
       " 47478: 0.0,\n",
       " 42781: 0.0,\n",
       " 57749: 0.0,\n",
       " 67073: 0.0,\n",
       " 45454: 0.0,\n",
       " 53547: 0.0,\n",
       " 35210: 0.0,\n",
       " 43401: 0.0,\n",
       " 18735: 0.0,\n",
       " 31026: 0.0,\n",
       " 52540: 1.0,\n",
       " 41335: 0.0,\n",
       " 41346: 0.0,\n",
       " 33077: 0.0,\n",
       " 43323: 0.0,\n",
       " 20861: 0.0,\n",
       " 18750: 0.0,\n",
       " 66132: 0.0,\n",
       " 49473: 1.0,\n",
       " 43384: 0.0,\n",
       " 12768: 0.0,\n",
       " 11179: 1.0,\n",
       " 43641: 0.0,\n",
       " 63686: 0.0,\n",
       " 17329: 0.0,\n",
       " 10838: 0.0,\n",
       " 21076: 1.0,\n",
       " 4084: 0.0,\n",
       " 10833: 0.0,\n",
       " 51790: 0.0,\n",
       " 49330: 0.0,\n",
       " 61619: 0.0,\n",
       " 56498: 0.0,\n",
       " 64066: 0.0,\n",
       " 43198: 0.0,\n",
       " 57920: 0.0,\n",
       " 23103: 0.0,\n",
       " 32959: 0.0,\n",
       " 10811: 0.0,\n",
       " 41530: 1.0,\n",
       " 14905: 0.0,\n",
       " 28864: 1.0,\n",
       " 59666: 0.0,\n",
       " 34990: 0.0,\n",
       " 2677: 0.0,\n",
       " 3356: 0.0,\n",
       " 34984: 0.0,\n",
       " 54296: 0.0,\n",
       " 31352: 0.0,\n",
       " 26786: 0.0,\n",
       " 23158: 0.0,\n",
       " 37027: 0.0,\n",
       " 59557: 1.0,\n",
       " 26959: 0.0,\n",
       " 31997: 1.0,\n",
       " 38636: 0.0,\n",
       " 19386: 0.0,\n",
       " 4721: 0.0,\n",
       " 53391: 1.0,\n",
       " 55916: 0.0,\n",
       " 39528: 0.0,\n",
       " 35431: 0.0,\n",
       " 43621: 1.0,\n",
       " 65709: 0.0,\n",
       " 60002: 1.0,\n",
       " 6709: 1.0,\n",
       " 49715: 0.0,\n",
       " 27112: 1.0,\n",
       " 48710: 0.0,\n",
       " 61958: 0.0,\n",
       " 57861: 0.0,\n",
       " 65734: 1.0,\n",
       " 515: 0.0,\n",
       " 14843: 0.0,\n",
       " 45562: 0.0,\n",
       " 29996: 0.0,\n",
       " 55543: 0.0,\n",
       " 53994: 0.0,\n",
       " 2296: 1.0,\n",
       " 8691: 0.0,\n",
       " 19223: 0.0,\n",
       " 33022: 1.0,\n",
       " 46522: 0.0,\n",
       " 3056: 0.0,\n",
       " 43499: 0.0,\n",
       " 2538: 0.0,\n",
       " 47359: 0.0,\n",
       " 10497: 1.0,\n",
       " 61678: 1.0,\n",
       " 16702: 0.0,\n",
       " 60596: 0.0,\n",
       " 2877: 0.0,\n",
       " 57543: 1.0,\n",
       " 25135: 0.0,\n",
       " 37418: 0.0,\n",
       " 43560: 0.0,\n",
       " 33435: 0.0,\n",
       " 51749: 1.0,\n",
       " 4644: 0.0,\n",
       " 19954: 0.0,\n",
       " 59934: 0.0,\n",
       " 33291: 0.0,\n",
       " 43545: 0.0,\n",
       " 29207: 1.0,\n",
       " 37082: 0.0,\n",
       " 13968: 0.0,\n",
       " 39772: 0.0,\n",
       " 39443: 0.0,\n",
       " 16337: 0.0,\n",
       " 6668: 0.0,\n",
       " 13737: 0.0,\n",
       " 15430: 0.0,\n",
       " 23437: 1.0,\n",
       " 7822: 0.0,\n",
       " 49935: 0.0,\n",
       " 28298: 0.0,\n",
       " 1673: 0.0,\n",
       " 32389: 1.0,\n",
       " 61058: 0.0,\n",
       " 40577: 0.0,\n",
       " 35153: 0.0,\n",
       " 38525: 1.0,\n",
       " 35476: 0.0,\n",
       " 36470: 0.0,\n",
       " 40565: 1.0,\n",
       " 49305: 0.0,\n",
       " 24178: 0.0,\n",
       " 65130: 0.0,\n",
       " 67176: 1.0,\n",
       " 48743: 0.0,\n",
       " 5734: 0.0,\n",
       " 60527: 0.0,\n",
       " 28256: 0.0,\n",
       " 44639: 0.0,\n",
       " 11869: 0.0,\n",
       " 61020: 1.0,\n",
       " 63067: 0.0,\n",
       " 22106: 0.0,\n",
       " 50777: 0.0,\n",
       " 65165: 0.0,\n",
       " 18063: 1.0,\n",
       " 40648: 0.0,\n",
       " 63120: 0.0,\n",
       " 53200: 0.0,\n",
       " 52933: 1.0,\n",
       " 28356: 0.0,\n",
       " 63529: 0.0,\n",
       " 48828: 0.0,\n",
       " 63162: 0.0,\n",
       " 54969: 0.0,\n",
       " 2813: 1.0,\n",
       " 38577: 0.0,\n",
       " 28336: 1.0,\n",
       " 34478: 0.0,\n",
       " 28333: 0.0,\n",
       " 11948: 0.0,\n",
       " 43436: 1.0,\n",
       " 28330: 1.0,\n",
       " 38569: 0.0,\n",
       " 50564: 0.0,\n",
       " 5797: 1.0,\n",
       " 20131: 0.0,\n",
       " 63132: 1.0,\n",
       " 56983: 0.0,\n",
       " 44997: 0.0,\n",
       " 5781: 0.0,\n",
       " 48788: 1.0,\n",
       " 63122: 0.0,\n",
       " 46680: 0.0,\n",
       " 5719: 0.0,\n",
       " 28246: 1.0,\n",
       " 4023: 0.0,\n",
       " 11794: 0.0,\n",
       " 3601: 0.0,\n",
       " 66100: 1.0,\n",
       " 42497: 0.0,\n",
       " 22016: 1.0,\n",
       " 9723: 0.0,\n",
       " 36346: 1.0,\n",
       " 58984: 0.0,\n",
       " 11764: 1.0,\n",
       " 21997: 1.0,\n",
       " 46963: 1.0,\n",
       " 60902: 0.0,\n",
       " 1938: 0.0,\n",
       " 13795: 0.0,\n",
       " 48609: 0.0,\n",
       " 5600: 0.0,\n",
       " 40413: 1.0,\n",
       " 19932: 0.0,\n",
       " 17883: 0.0,\n",
       " 11737: 1.0,\n",
       " 19928: 0.0,\n",
       " 67334: 0.0,\n",
       " 54742: 0.0,\n",
       " 15826: 0.0,\n",
       " 67025: 0.0,\n",
       " 30227: 0.0,\n",
       " 17941: 0.0,\n",
       " 58903: 0.0,\n",
       " 9779: 0.0,\n",
       " 56916: 0.0,\n",
       " 38480: 0.0,\n",
       " 22421: 1.0,\n",
       " 67144: 0.0,\n",
       " 9791: 1.0,\n",
       " 56893: 0.0,\n",
       " 17980: 1.0,\n",
       " 30870: 0.0,\n",
       " 50744: 0.0,\n",
       " 1591: 0.0,\n",
       " 40502: 0.0,\n",
       " 43969: 1.0,\n",
       " 60101: 0.0,\n",
       " 62541: 0.0,\n",
       " 46637: 0.0,\n",
       " 15191: 1.0,\n",
       " 63017: 0.0,\n",
       " 56872: 0.0,\n",
       " 26149: 0.0,\n",
       " 16000: 0.0,\n",
       " 17944: 0.0,\n",
       " 30236: 0.0,\n",
       " 19995: 0.0,\n",
       " 61716: 0.0,\n",
       " 53666: 0.0,\n",
       " 61133: 1.0,\n",
       " 62927: 0.0,\n",
       " 51128: 0.0,\n",
       " 4021: 0.0,\n",
       " 25269: 0.0,\n",
       " 48049: 0.0,\n",
       " 67503: 0.0,\n",
       " 64573: 1.0,\n",
       " 24489: 0.0,\n",
       " 44965: 1.0,\n",
       " 32381: 1.0,\n",
       " 40866: 0.0,\n",
       " 20377: 0.0,\n",
       " 3990: 0.0,\n",
       " 49045: 0.0,\n",
       " 51090: 1.0,\n",
       " 24465: 0.0,\n",
       " 62890: 0.0,\n",
       " 56659: 0.0,\n",
       " 26497: 1.0,\n",
       " 59262: 0.0,\n",
       " 17604: 0.0,\n",
       " 42876: 0.0,\n",
       " 8058: 0.0,\n",
       " 32632: 1.0,\n",
       " 1909: 1.0,\n",
       " 61299: 0.0,\n",
       " 34099: 0.0,\n",
       " 38932: 0.0,\n",
       " 53181: 0.0,\n",
       " 37336: 0.0,\n",
       " 36798: 0.0,\n",
       " 55291: 0.0,\n",
       " 8186: 0.0,\n",
       " 20469: 0.0,\n",
       " 51595: 0.0,\n",
       " 12275: 0.0,\n",
       " 55282: 0.0,\n",
       " 28656: 0.0,\n",
       " 18414: 0.0,\n",
       " 63466: 1.0,\n",
       " 26601: 0.0,\n",
       " 67560: 1.0,\n",
       " 45030: 1.0,\n",
       " 13260: 1.0,\n",
       " 32737: 0.0,\n",
       " 53213: 0.0,\n",
       " 45020: 1.0,\n",
       " 7240: 0.0,\n",
       " 6104: 0.0,\n",
       " 34771: 1.0,\n",
       " 8146: 0.0,\n",
       " 34418: 0.0,\n",
       " 41970: 0.0,\n",
       " 12239: 0.0,\n",
       " 8142: 0.0,\n",
       " 9988: 0.0,\n",
       " 30575: 0.0,\n",
       " 40813: 0.0,\n",
       " 37016: 0.0,\n",
       " 37352: 0.0,\n",
       " 3862: 0.0,\n",
       " 60516: 0.0,\n",
       " 39878: 1.0,\n",
       " 50957: 0.0,\n",
       " 50956: 1.0,\n",
       " 3851: 0.0,\n",
       " 55044: 1.0,\n",
       " 30463: 1.0,\n",
       " 31437: 0.0,\n",
       " 39080: 0.0,\n",
       " 16120: 0.0,\n",
       " 67318: 0.0,\n",
       " 34549: 0.0,\n",
       " 24307: 0.0,\n",
       " 9969: 0.0,\n",
       " 55523: 0.0,\n",
       " 67307: 0.0,\n",
       " 65256: 0.0,\n",
       " 28384: 0.0,\n",
       " 64782: 1.0,\n",
       " 16317: 0.0,\n",
       " 55839: 0.0,\n",
       " 34520: 0.0,\n",
       " 54999: 1.0,\n",
       " 14037: 0.0,\n",
       " 36635: 0.0,\n",
       " 3868: 0.0,\n",
       " 46877: 0.0,\n",
       " 53628: 0.0,\n",
       " 25530: 0.0,\n",
       " 20318: 0.0,\n",
       " 40794: 0.0,\n",
       " 63319: 0.0,\n",
       " 11233: 1.0,\n",
       " 32298: 0.0,\n",
       " 48600: 0.0,\n",
       " 3920: 0.0,\n",
       " 67407: 0.0,\n",
       " 16206: 1.0,\n",
       " 8935: 0.0,\n",
       " 3914: 0.0,\n",
       " 12656: 0.0,\n",
       " 12105: 0.0,\n",
       " 52554: 0.0,\n",
       " 52376: 0.0,\n",
       " 63291: 1.0,\n",
       " 16185: 0.0,\n",
       " 28467: 0.0,\n",
       " 65887: 0.0,\n",
       " 48943: 0.0,\n",
       " 46127: 0.0,\n",
       " 4240: 0.0,\n",
       " 40737: 0.0,\n",
       " 9680: 0.0,\n",
       " 24010: 0.0,\n",
       " 37020: 0.0,\n",
       " 47486: 0.0,\n",
       " 45325: 0.0,\n",
       " 21589: 0.0,\n",
       " 52308: 0.0,\n",
       " 65524: 0.0,\n",
       " 42065: 0.0,\n",
       " 19535: 0.0,\n",
       " 48205: 0.0,\n",
       " 7244: 0.0,\n",
       " 11339: 0.0,\n",
       " 31817: 0.0,\n",
       " 53434: 1.0,\n",
       " 46945: 0.0,\n",
       " 29765: 0.0,\n",
       " 13642: 1.0,\n",
       " 47700: 0.0,\n",
       " 62526: 0.0,\n",
       " 18083: 1.0,\n",
       " 64572: 0.0,\n",
       " 64571: 0.0,\n",
       " 33850: 0.0,\n",
       " 39991: 0.0,\n",
       " 27695: 1.0,\n",
       " 13356: 1.0,\n",
       " 1063: 0.0,\n",
       " 66131: 0.0,\n",
       " 36383: 0.0,\n",
       " 13408: 0.0,\n",
       " 62642: 0.0,\n",
       " 58421: 0.0,\n",
       " 9383: 1.0,\n",
       " 52390: 1.0,\n",
       " 27808: 0.0,\n",
       " 33951: 0.0,\n",
       " 32871: 0.0,\n",
       " 46232: 0.0,\n",
       " 1173: 0.0,\n",
       " 64660: 0.0,\n",
       " 40081: 0.0,\n",
       " 46223: 0.0,\n",
       " 31556: 1.0,\n",
       " 3212: 0.0,\n",
       " 23690: 0.0,\n",
       " 50313: 0.0,\n",
       " 11400: 0.0,\n",
       " 21639: 0.0,\n",
       " 44908: 0.0,\n",
       " 11385: 0.0,\n",
       " 25717: 0.0,\n",
       " 31855: 1.0,\n",
       " 15470: 1.0,\n",
       " 31269: 0.0,\n",
       " 42090: 0.0,\n",
       " 60520: 0.0,\n",
       " 25701: 1.0,\n",
       " 13347: 0.0,\n",
       " 3734: 1.0,\n",
       " 27680: 1.0,\n",
       " 44058: 0.0,\n",
       " 31694: 1.0,\n",
       " 41932: 1.0,\n",
       " 9161: 1.0,\n",
       " 13254: 0.0,\n",
       " 37829: 0.0,\n",
       " 19393: 0.0,\n",
       " 19391: 0.0,\n",
       " 5052: 0.0,\n",
       " 35543: 1.0,\n",
       " 39864: 0.0,\n",
       " 62389: 0.0,\n",
       " 2996: 0.0,\n",
       " 1184: 0.0,\n",
       " 60337: 0.0,\n",
       " 5035: 0.0,\n",
       " 40228: 1.0,\n",
       " 31655: 0.0,\n",
       " 5180: 0.0,\n",
       " 64417: 0.0,\n",
       " 60319: 1.0,\n",
       " 37790: 0.0,\n",
       " 29591: 0.0,\n",
       " 54868: 0.0,\n",
       " 5012: 0.0,\n",
       " 9588: 0.0,\n",
       " 5071: 0.0,\n",
       " 34335: 0.0,\n",
       " 10746: 0.0,\n",
       " 23542: 0.0,\n",
       " 1046: 1.0,\n",
       " 66579: 0.0,\n",
       " 29712: 0.0,\n",
       " 16380: 0.0,\n",
       " 37496: 0.0,\n",
       " 11668: 0.0,\n",
       " 9221: 0.0,\n",
       " 50280: 0.0,\n",
       " 40960: 1.0,\n",
       " 13312: 0.0,\n",
       " 19454: 0.0,\n",
       " 10580: 0.0,\n",
       " 5081: 0.0,\n",
       " 19444: 1.0,\n",
       " 60403: 1.0,\n",
       " 64496: 1.0,\n",
       " 21487: 0.0,\n",
       " 1003: 0.0,\n",
       " 15332: 0.0,\n",
       " 5089: 0.0,\n",
       " 39904: 0.0,\n",
       " 7134: 0.0,\n",
       " 31707: 0.0,\n",
       " 22496: 0.0,\n",
       " 34647: 1.0,\n",
       " 31923: 0.0,\n",
       " 44489: 0.0,\n",
       " 52626: 0.0,\n",
       " 4227: 0.0,\n",
       " 37524: 0.0,\n",
       " 56184: 1.0,\n",
       " 46464: 0.0,\n",
       " 7551: 0.0,\n",
       " 36208: 0.0,\n",
       " 66923: 0.0,\n",
       " 7530: 0.0,\n",
       " 48488: 1.0,\n",
       " 66916: 1.0,\n",
       " 28002: 0.0,\n",
       " 25952: 0.0,\n",
       " 42268: 0.0,\n",
       " 2691: 0.0,\n",
       " 64861: 0.0,\n",
       " 22119: 0.0,\n",
       " 48474: 1.0,\n",
       " 62809: 0.0,\n",
       " 63476: 0.0,\n",
       " 12277: 0.0,\n",
       " 14827: 1.0,\n",
       " 56653: 0.0,\n",
       " 8947: 0.0,\n",
       " 63791: 0.0,\n",
       " 50500: 0.0,\n",
       " 33641: 0.0,\n",
       " 62868: 0.0,\n",
       " 51623: 0.0,\n",
       " 62870: 0.0,\n",
       " 27079: 0.0,\n",
       " 58823: 0.0,\n",
       " 12594: 0.0,\n",
       " 48307: 0.0,\n",
       " 5568: 0.0,\n",
       " 66445: 0.0,\n",
       " 62910: 0.0,\n",
       " 40381: 0.0,\n",
       " 67004: 0.0,\n",
       " 30139: 0.0,\n",
       " 5435: 0.0,\n",
       " 46258: 1.0,\n",
       " 54710: 0.0,\n",
       " 3505: 1.0,\n",
       " 55321: 1.0,\n",
       " 56748: 0.0,\n",
       " 19882: 0.0,\n",
       " 18343: 1.0,\n",
       " 40359: 0.0,\n",
       " 44453: 0.0,\n",
       " 36258: 0.0,\n",
       " 12786: 0.0,\n",
       " 5536: 1.0,\n",
       " 64924: 0.0,\n",
       " 19866: 0.0,\n",
       " 30018: 1.0,\n",
       " 21476: 0.0,\n",
       " 36818: 1.0,\n",
       " 40250: 0.0,\n",
       " 9452: 0.0,\n",
       " 15594: 1.0,\n",
       " 27880: 0.0,\n",
       " 25827: 1.0,\n",
       " 21730: 0.0,\n",
       " 15830: 0.0,\n",
       " 67122: 1.0,\n",
       " 40928: 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
